{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTJrWN_45i2W"
      },
      "source": [
        "# Optimisation de portefeuille d'actions\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "puNumnI1M6eA"
      },
      "source": [
        "# Membres du groupe:\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "> Guelfane Abdelaziz    (Implémentation et simulations numériques)\n",
        "\n",
        "> Reda Benkirane    (Analyse mathématique)\n",
        "\n",
        "> Ismail Oulkhir    ( description de la problématique et du phénomène modélisé & formulation et Analyse mathématique)\n",
        "\n",
        "> Omar Bellmir    (Analyse mathématique)\n",
        "\n",
        "> Imad Absri    (Formulation mathématique sous forme d'un problème d'optimisation bien posé)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0shpvAEfHBc"
      },
      "source": [
        "## 1 Présentation de la problématique<a id=\"0\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "covbttJVfVgK"
      },
      "source": [
        "Le projet d'Optimisation de Portefeuille est une initiative qui vise à maximiser les rendements financiers tout en minimisant les risques associés à la gestion d'un portefeuille d'investissement. Dans le monde des marchés financiers, les investisseurs sont constamment à la recherche de stratégies permettant de générer des profits tout en protégeant leur capital contre les fluctuations et les incertitudes du marché. Ainsi on se confronte aux problèmes suivant :\n",
        "> Comment modéliser les prix des actifs ainsi que les portefeuilles ?\n",
        "\n",
        ">Comment peut-on exprimer le problème de recherche d'un portefeuille performant en respectant un seuil maximal de risque spécifié ?\n",
        "\n",
        ">Comment traduire mathématiquement et résoudre le problème en utilisant\n",
        "des outils d'optimisation ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "psDtA_HqrX35"
      },
      "source": [
        "## 2 Formulation Mathématique<a id=\"1\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GaNFXxUpLP5p"
      },
      "source": [
        "On suppose le marché à 2 dates t = 0 et t = 1.\n",
        "\n",
        "Il existe N actifs risqués, et 1 actif sans risque.\n",
        "\n",
        "L'actif sans risque vaut 1 en t = 0 et 1+r en t = 1.\n",
        "\n",
        "On note $p_i(t)$ le prix de l'actif i à la date t, avec $i ∈ \\{1, ..., N \\}$ et $t ∈ \\{0, 1\\}$\n",
        "On note $y_i$ le rapport $\\frac{p_i(1)}{p_i(0)}$.\n",
        "- Afin de modéliser les valeurs futures des actifs, on utilise des variables aléatoires, pour cela on se donne un espace de probabilité $(\\Omega, \\mathcal{F}, \\mathbb{P})$\n",
        "- $R=\\left(\\begin{array}{c}r_1 \\\\ \\vdots \\\\ r_N\\end{array}\\right)$ vecteur aléatoire à valeurs dans $\\mathbb{R}^N$ qu'on suppose dans $L^2$. Ce vecteur représente le rendement des investiments dans les actifs donnés.\n",
        "- On note son espérance\n",
        "$$\n",
        "\\mu=\\mathbb{E}[R] \\in \\mathbb{R}^N\n",
        "$$\n",
        "et sa matrice de variance covariance\n",
        "$$\n",
        "\\Omega=\\operatorname{Var}(Y)=\\left(\\mathbb{C o v}\\left(Y_i, Y_j\\right)_{1 \\leq i, j \\leq N}\\right) \\in \\mathbb{S}_n^{++}(\\mathbb{R})\n",
        "$$\n",
        "Donc en particulier $\\Omega$ inversible.\n",
        "- On suppose que $\\forall i \\in\\{1, \\ldots, N\\}$ on a $\\mu_i>1+r$\n",
        "- Un portefeuille est définit par le couple $\\left(x_0, x\\right) \\in \\mathbb{R} \\times \\mathbb{R}^N$, indiquant la quantité d'actif qu'il contient.\n",
        "- La valeur du portefeuille aux différents instants est donc\n",
        "$$\n",
        "\\left\\{\\begin{array}{l}\n",
        "V_0\\left(x_0, x\\right)=x_0+\\sum_{i=1}^N x_i p_i(0) \\\\\n",
        "V_1\\left(x_0, a\\right)=x_0(1+r)+\\sum_{i=1}^N x_i p_i(1)=x_0(1+r)+\\sum_{i=1}^N x_i p_i(0) r_i\n",
        "\\end{array}\\right.\n",
        "$$\n",
        "Sous forme matricielle:\n",
        "Valeurs du portefeuille\n",
        "$$\n",
        "\\left\\{\\begin{array}{l}\n",
        "V_0\\left(x_0, x\\right)=x_0+x^T p(0) \\\\\n",
        "V_1\\left(x_0, x\\right)=x_0(1+r)+x^T \\operatorname{diag}(p(0)) R\n",
        "\\end{array}\\right.\n",
        "$$\n",
        "où\n",
        "$$\n",
        "p(0)=\\left(\\begin{array}{c}\n",
        "p_1(0) \\\\\n",
        "\\vdots \\\\\n",
        "p_N(0)\n",
        "\\end{array}\\right)\n",
        "$$\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNVGNvjdnSSh"
      },
      "source": [
        "### Formulation mathématique sous forme d'un problème d'optimisation bien posé:\n",
        " - On considère un portefeuille de valeur $v$ en $t=0$, i.e $V_0\\left(a_0, a\\right)=v$, on se donne un niveau maximal de variance $\\sigma^2$, on veut naturellement maximiser l'espérance de gain.\n",
        "- On cherche à trouver les couples $\\left(a_0, a\\right)$ qui résolvent:\n",
        "$$\n",
        "\\begin{array}{ll}\n",
        "\\max _{a_0, a} & \\mathbb{E}\\left[V_1\\left(a_0, a\\right)\\right] \\\\\n",
        "\\text { sous } & \\operatorname{Var}\\left[V_1\\left(a_0, a\\right)\\right] \\leq \\sigma^2 \\\\\n",
        "& V_0\\left(a_0, a\\right)=v\n",
        "\\end{array}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IwB4-XZ7zl9P"
      },
      "source": [
        "## 3 Analyse Mathématique du problème d'optimisation<a id=\"1\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cU186fdM2aVb"
      },
      "source": [
        "On note\n",
        "$$\n",
        "w_x= diag(p(0))x = \\left(\\begin{array}{c}\n",
        "p_1(0)*x_1 \\\\\n",
        "\\vdots \\\\\n",
        "p_N(0)* x_N\n",
        "\\end{array}\\right)\n",
        "$$\n",
        "\n",
        "Donc\n",
        "$$\n",
        "\\left\\{\\begin{array}{l}\n",
        "V_0\\left(x_0, x\\right)=x_0+ w_x^T e \\\\\n",
        "V_1\\left(x_0, a\\right)=x_0(1+r)+w_x^TR\n",
        "\\end{array}\\right.\n",
        "$$\n",
        "\n",
        "où $e = (1 … 1)^T$\n",
        "En général pour un vecteur aléatoire $X ∈ L^2$ et un vecteur réel $λ$ de même\n",
        "dimension, $Var(λT X) = λ^T Var(X)λ$.\n",
        "\n",
        "On en déduit :\n",
        "$$\n",
        "\\left\\{\\begin{array}{l}\n",
        "\\mathbb{E}(V_1(x_0,x))=x_0(1+r)+w_x^T\\mu \\\\\n",
        "Var(V_1(x_0,x))=w_x^T\\Omega w_x\n",
        "\\end{array}\\right.\n",
        "$$\n",
        "\n",
        "Une forme équivalente de ce problème d'optimisation est :\n",
        "  \\begin{array}{ll}\n",
        "\\max _{w_x \\in \\mathbb{R}^N} & w_x^T\\tilde{μ} \\\\\n",
        "\\text { sous } & w_x^T\\Omega w_x \\leq \\sigma^2 \\\\\n",
        "\\end{array}\n",
        "\n",
        "où $\\tilde{μ} = \\mu -(1+r)e $\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myKi_YjVh_nM"
      },
      "source": [
        "#Condition de Salter\n",
        "Pour un problème convexe différentiable les conditions de KKT sont\n",
        "nécessaires et suffisantes pour l'optimalité, en d'autre terme un point x est\n",
        "optimal pour le primal si on réussit à trouver λ et μ de sorte que (x, λ, μ)\n",
        "satisfasse les conditions de KKT."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sd81g-927x0f"
      },
      "source": [
        "###Mise sous forme de problème de minimisation sous contrainte\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37IhruzF7_Ye"
      },
      "source": [
        "La forme canonique d'un problème d'optimisation sous contraintes sur $x \\in \\mathbb{R}^N$ est :\n",
        "  \\begin{array}{ll}\n",
        "\\min &J(x) \\\\\n",
        "\\text { sous contraintes } & f_i(x) \\leq 0,&  i=1\\dots,m \\\\\n",
        "&h_i(x)=0,&j=1,\\dots,p\n",
        "\\end{array}\n",
        "Avec toutes les fonctions  à valeurs dans $\\mathbb{R}.$\n",
        "\n",
        "En réécrivant le problème équivalent sous problème de minimisation:\n",
        "  \\begin{array}{ll}\n",
        "-\\min _{w_x \\in \\mathbb{R}^N} & -w_x^T\\tilde{μ} \\\\\n",
        "\\text { sous } & w_x^T\\Omega w_x \\leq \\sigma^2 \\\\\n",
        "\\end{array}\n",
        "En appliquant ce qu'on a vu en cours pour l'optimisation sous contraintes:\n",
        "\n",
        "$J(x)= -w_x^T\\tilde{μ} $ est linéaire donc convexe.\n",
        "\n",
        "$f_1(x)=w_x^T\\Omega w_x -\\sigma^2$ qui est convexe car $\\nabla^2 f_1(x)=2\\Omega \\in \\mathbb{S}_n^{++}(\\mathbb{R}) $\n",
        "\n",
        "Dans le cas $\\sigma=0$ , on investit tout dans l'actif sans risque.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o34Cse37j68T"
      },
      "source": [
        "#Existence et Unicité\n",
        "Dans le cas  $\\sigma \\ge 0$ , en prenant x=0 on trouve que $w_x^T\\Omega w_x   =0 \\le \\sigma^2 $ et donc 0 satisfait la condition de Slater : $f_{1}(0)=0 \\le 0$.\n",
        "Il existe donc une et une seule solution optimale pour le problème d'optimisation convexe différentiable, sa forme analytique sera donnée par la suite."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYhbH_9xCWWT"
      },
      "source": [
        "###Conditions d'optimalités\n",
        " et donc les conditions de KKT s'écrivent:\n",
        "\n",
        ">$w_x^T\\Omega w_x -\\sigma^2 \\leq 0$ (1)\n",
        "\n",
        ">$ \\lambda \\geq 0$ (2)\n",
        "\n",
        ">$\\lambda(w_x^T\\Omega w_x -\\sigma^2)=0 $ (3)\n",
        "\n",
        ">$-\\tilde{\\mu}+\\lambda\\Omega x=0$ (4)\n",
        "\n",
        "sont nécessaires et suffisantes pour l'optimalité de ce problème convexe.\n",
        "\n",
        "La condition 3 implique $ \\lambda=0 $ ou $w_x^T\\Omega w_x -\\sigma^2=0$\n",
        "\n",
        "Si $\\lambda =0 $ alors la condition 4 donne $\\tilde{\\mu} =0 $ ou $\\mu>(1+r)e$ donc $\\tilde{\\mu} \\ge 0$ d'ou $\\lambda \\ge 0$ et c'est l'autre terme qui s'annule.\n",
        "\n",
        "Cela fait sens, la variance du portefeuille de gain maximal atteindra la\n",
        "variance maximale permise $\\sigma^2$.\n",
        "\n",
        "L'équation 4 donne $x=\\frac{1}{\\lambda}\\Omega^{-1}\\tilde{\\mu}$\n",
        "\n",
        "En réinjectant tout cela dans les équations initiales on trouve l'expression pour notre solution :\n",
        "        \\begin{array}{l}\n",
        "x^*\\left(\\lambda^*\\right)=\\frac{1}{\\lambda^*} \\operatorname{diag}(p(0))^{-1} \\Omega^{-1} \\tilde{\\mu} \\\\\n",
        "x_0^*\\left(\\lambda^*\\right)=v-\\frac{1}{\\lambda^*} \\tilde{\\mu}^T \\Omega^{-1} e \\\\\n",
        "\\lambda^*=\\frac{1}{\\sigma} \\sqrt{\\tilde{\\mu}^T \\Omega^{-1} \\tilde{\\mu}}\n",
        "\\end{array}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "msZj6jG07Q-d"
      },
      "source": [
        "## Sélection d'un algorithme de résolution\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-Jnopll__dr"
      },
      "source": [
        " # <center> Méthode du gradient projeté"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGEAvUlO8BT7"
      },
      "source": [
        "L'objectif d'optimisation de portefueille consiste à maximiser les rendements financiers. La méthode du gradient projeté permet de rechercher efficacement cette maximisation en propjetant la solution du problème d'optimisation sur l'espace des solutions admissivbles défini par $K = \\{x \\in \\mathbb{{R}}^n,  x^T\\Omega x \\leq \\sigma^2\\}$, garantissant ainsi que la solution respecte les contraintes imposées.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amRn4mwjJjiv"
      },
      "source": [
        "Nous décrivons maintenant la méthode du gradient projeté. Comme son nom l’indique, on cherche à résoudre un problème sous contraintes\n",
        "$$ \\arg\\min\\{J(x), x \\in K\\} $$\n",
        "\n",
        "\n",
        "où $K = \\{x \\in \\mathbb{{R}}^n,  x^T\\Omega x \\leq \\sigma^2\\}$\n",
        "\n",
        "\n",
        "par une méthode de type descente de gradient. Le problème est que le gradient de $J$ peut nous faire\n",
        "sortir de $K$. L’idée est donc de considérer le projeté du gradient. Les itérations sont de la forme (ici pour un gradient projeté à pas constant)\n",
        "\n",
        "Nonobstant, la méthode du gradient projeté s’inspire de la méthode du\n",
        "gradient.\n",
        "\n",
        "Dans le cas sans contraintes, l’algorithme du gradient, qui est une méthode de descente, s’écrit sous la forme générique :\n",
        "$$\n",
        "\\left\\{\\begin{array}{l}\n",
        "\\ x_0  \\in \\mathbb{{R}}^n \\\\\n",
        "x_{k+1}=x_k + ρ_kd_k, d_k\\in \\mathbb{{R}}^n-\\{0_{\\mathbb{{R}}^n}\\}, ρ_k \\in \\mathbb{R^{+*}}\n",
        "\\end{array}\\right.\n",
        "$$\n",
        "\n",
        "$ρ_k$ et $d_k$ sont choisis de telle sorte que $J(x_k+ρ_kd_k)\\leq J(x_k)\n",
        "$\n",
        ", cependant, c'est là où réside le problème, c'est lorsqu’on minimise sur  l'ensemble de contraintes $K$ et que $x_k ∈ K$ on n’est pas sûr avec la formulation précédente que l’itéré $x_{k+1}=x_k + ρ_kd_k$ appartienne à $K$.\n",
        "\n",
        "Il sera donc nécessaire de  \"ramener\" l'élément dans $K$, ce qui est réalisé en effectuant une projection sur $K$.\n",
        "\n",
        "C'est  grâce à cette propriété qu'on a pu distinguer les choix parmi les autres algorithmes, et opter pour la méthode du gradient projeté.\n",
        "\n",
        "On réalise cette dernière opération grâce à une projection sur $K$. On appelle projection sur $K$ l'application $P_K \\colon \\mathbb{{R}}^n \\to \\mathbb{R}$ définie par\n",
        "<center> $$P_K(x):=\\arg\\min\\{\\left\\|k-x\\right\\|, k \\in K\\} $$\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aiG06fbwDvrH"
      },
      "source": [
        "\n",
        "##Algorithme de la méthode du gradient projeté\n",
        "\n",
        "**1. Initialisation:** $k=0:$ choix de $x_0$ et de $\\rho_0>0$\n",
        "\n",
        "**2. Iteration $k$  :**   $x_{k+1}=\\ P_K\\left(x_k-\\rho_k \\nabla J\\left(x_k\\right)\\right)$;\n",
        "\n",
        "**3. Critère d'arrêt:** Si $\\left\\|x_{k+1}-x_k\\right\\|<\\varepsilon$, Break\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phUiUYAKpdM0"
      },
      "source": [
        "### Convergence de l'algorithme"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1ZYrs-Fy3_1"
      },
      "source": [
        "On a la fonction objective $C^1$ de $\\mathbb{R}^n$ dans $\\mathbb{R}$, le minimum existe et est unique, puisque dans ce cas la fonction est linéaire, le gradient projeté converge vers le point minimum."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jrGOIwzpylAP"
      },
      "source": [
        "## 4 Implémentation et simulations numériques <a id=\"1\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2q-CdnFGhKkB"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy.optimize import minimize\n",
        "\n",
        "def Gradient_projete(mu_tilde, omega, sigma_carre, x0, alpha, tol=1e-6, max_iter=1000):\n",
        "    x = x0\n",
        "    traj = [x]\n",
        "\n",
        "    def projection_func(x):\n",
        "        return np.linalg.norm(x - x0)\n",
        "\n",
        "    for iter in range(max_iter):\n",
        "        x_old = x\n",
        "\n",
        "        # Prédiction / descente de gradient\n",
        "        grad = -mu_tilde\n",
        "        x = x - alpha * grad\n",
        "\n",
        "        # Projection sur l'ensemble K\n",
        "        constraint = {'type': 'ineq', 'fun': lambda x: x.T.dot(omega).dot(x) - sigma_carre}\n",
        "        bounds = [(None, None)] * len(x)\n",
        "        result = minimize(projection_func, x, method='SLSQP', constraints=constraint, bounds=bounds)\n",
        "        x = result.x\n",
        "\n",
        "        err = np.linalg.norm(x_old - x)\n",
        "\n",
        "        traj.append(x)\n",
        "\n",
        "        # Vérification de la convergence\n",
        "        if err < tol:\n",
        "            print('L\\'algorithme a convergé après', iter + 1, 'itérations.')\n",
        "            break\n",
        "\n",
        "\n",
        "    return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGagS82ARVVb",
        "outputId": "f905e35f-74b0-41c8-b199-3744c24063c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "L'algorithme a convergé après 3 itérations.\n",
            "Répartition optimale des actifs dans le portefeuille :\n",
            "Actif 1: 0.21072255886537458\n",
            "Actif 2: 0.3261626320727165\n",
            "Actif 3: 0.5201645683943722\n"
          ]
        }
      ],
      "source": [
        "# Exemple d'utilisation\n",
        "mu_tilde = np.array([0.1, 0.2, 0.15])  # Rendements espérés des actifs\n",
        "omega = np.array([[0.04, 0.02, 0.01], [0.02, 0.09, 0.03], [0.01, 0.03, 0.05]])  # Matrice de variance-covariance\n",
        "sigma_carre = 0.04  # Variance maximale autorisée\n",
        "x0 = np.array([0.2, 0.3, 0.5])  # Répartition initiale des actifs dans le portefeuille\n",
        "alpha = 0.1  # Paramètre de pas\n",
        "epsilon = 0.001  # Critère d'arrêt\n",
        "\n",
        "optimal_valeurs = Gradient_projete(mu_tilde, omega, sigma_carre, x0, alpha, tol=1e-6, max_iter=1000)\n",
        "print(\"Répartition optimale des actifs dans le portefeuille :\")\n",
        "for i, valeur in enumerate(optimal_valeurs):\n",
        "    print(f\"Actif {i+1}: {valeur}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37cbXfaNk3aK",
        "outputId": "be64a660-14f6-414c-e742-6c4a518d426e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Répartition optimale des actifs dans le portefeuille :\n",
            "Actif 1: 0.15434123083664117\n",
            "Actif 2: 0.40521482323524116\n",
            "Actif 3: 0.4404439459280821\n",
            "Nombre d'itérations nécessaires : 2\n"
          ]
        }
      ],
      "source": [
        "import cvxpy as cp\n",
        "import numpy as np\n",
        "\n",
        "def optimize_portfolio(mu, omega, sigma_squared, tolerance=1e-6):\n",
        "    n = len(mu)  # Nombre d'actifs\n",
        "\n",
        "    # Variables de décision\n",
        "    x = cp.Variable(n, nonneg=True)  # Répartition des actifs dans le portefeuille\n",
        "\n",
        "    # Problème d'optimisation\n",
        "    objective = cp.Maximize(mu @ x)\n",
        "    constraints = [x @ omega @ x <= sigma_squared, cp.sum(x) == 1]\n",
        "\n",
        "    # Résolution du problème d'optimisation avec compteur\n",
        "    problem = cp.Problem(objective, constraints)\n",
        "    iterations = 0  # Compteur d'itérations\n",
        "    prev_solution = None  # Solution précédente\n",
        "    while True:\n",
        "        problem.solve()\n",
        "        if problem.status != cp.OPTIMAL:\n",
        "            break\n",
        "        iterations += 1\n",
        "        if prev_solution is not None and np.linalg.norm(x.value - prev_solution) <= tolerance:\n",
        "            break\n",
        "        prev_solution = x.value.copy()\n",
        "\n",
        "    # Récupération de la solution optimale\n",
        "    optimal_valeurs = x.value\n",
        "\n",
        "    return optimal_valeurs, iterations\n",
        "\n",
        "# Exemple d'utilisation\n",
        "mu = np.array([0.1, 0.2, 0.15])  # Rendements espérés des actifs\n",
        "omega = np.array([[0.04, 0.02, 0.01], [0.02, 0.09, 0.03], [0.01, 0.03, 0.05]])  # Matrice de variance-covariance\n",
        "sigma_carre = 0.04  # Variance maximale autorisée\n",
        "\n",
        "optimal_valeurs, iterations = optimize_portfolio(mu, omega, sigma_carre)\n",
        "print(\"Répartition optimale des actifs dans le portefeuille :\")\n",
        "for i, valeur in enumerate(optimal_valeurs):\n",
        "    print(f\"Actif {i+1}: {valeur}\")\n",
        "print(\"Nombre d'itérations nécessaires :\", iterations)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Comparaison des resultats des deux algorithmes : précision et vitesse de convergence /nombre d'iterations"
      ],
      "metadata": {
        "id": "DnSqG1orrWSX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jg4UXHFU_eH8",
        "outputId": "f10529bc-488c-4759-cb0a-e5e9f934f588"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Méthode Gradient Projeté - Répartition optimale des actifs dans le portefeuille :\n",
            "Actif 1: 0.21072277420563215\n",
            "Actif 2: 0.32616551551503425\n",
            "Actif 3: 0.5201607118310778\n",
            "Méthode cvxpy - Répartition optimale des actifs dans le portefeuille :\n",
            "Répartition optimale des actifs dans le portefeuille :\n",
            "Actif 1: 0.15434123083664117\n",
            "Actif 2: 0.40521482323524116\n",
            "Actif 3: 0.4404439459280821\n",
            "Temps d'exécution - Méthode Gradient Projeté: 2.7804183959960938 secondes\n",
            "Temps d'exécution - Méthode cvxpy: 0.013319015502929688 secondes\n"
          ]
        }
      ],
      "source": [
        "import cvxpy as cp\n",
        "import numpy as np\n",
        "from scipy.optimize import minimize\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Exemple d'utilisation et comparaison des méthodes\n",
        "mu_tilde = np.array([0.1, 0.2, 0.15])  # Rendements espérés des actifs\n",
        "omega = np.array([[0.04, 0.02, 0.01], [0.02, 0.09, 0.03], [0.01, 0.03, 0.05]])  # Matrice de variance-covariance\n",
        "sigma_carre = 0.04  # Variance maximale autorisée\n",
        "\n",
        "mu_tilde = -mu\n",
        "sigma_carre = sigma_carre\n",
        "x0 = np.array([0.2, 0.3, 0.5])  # Répartition initiale des actifs dans le portefeuille\n",
        "alpha = 0.1  # Paramètre de pas\n",
        "\n",
        "# Méthode 1 : Gradient Projeté\n",
        "start_time_1 = time.time()\n",
        "optimal_valeurs_1 = Gradient_projete(mu_tilde, omega, sigma_carre, x0, alpha, tol=1e-6, max_iter=1000)\n",
        "execution_time_1 = time.time() - start_time_1\n",
        "\n",
        "# Méthode 2 : cvxpy\n",
        "start_time_2 = time.time()\n",
        "tolerance=1e-6\n",
        "optimal_valeurs_2 = optimize_portfolio(mu, omega, sigma_carre)\n",
        "execution_time_2 = time.time() - start_time_2\n",
        "\n",
        "# Comparaison des résultats\n",
        "print(\"Méthode Gradient Projeté - Répartition optimale des actifs dans le portefeuille :\")\n",
        "for i, valeur in enumerate(optimal_valeurs_1):\n",
        "    print(f\"Actif {i+1}: {valeur}\")\n",
        "\n",
        "print(\"Méthode cvxpy - Répartition optimale des actifs dans le portefeuille :\")\n",
        "print(\"Répartition optimale des actifs dans le portefeuille :\")\n",
        "for i, valeur in enumerate(optimal_valeurs):\n",
        "    print(f\"Actif {i+1}: {valeur}\")\n",
        "\n",
        "\n",
        "\n",
        "# Affichage des temps d'exécution\n",
        "print(\"Temps d'exécution - Méthode Gradient Projeté:\", execution_time_1, \"secondes\")\n",
        "print(\"Temps d'exécution - Méthode cvxpy:\", execution_time_2, \"secondes\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "On observe des différences entre les deux méthodes en termes de répartition des actifs. On voit clairement que la résultats relatifs aux actifs sont légèrement différents, le temps d'exécution pour la méthode du **gradient projeté** est de 2.78 secondes, tandis que le temps de convergence pour la méthode **cvxpy** est de 0.013 seconde. Donc en termes de vitesse de convergence, la méthode cvxpy parait être plus rapide que celle du gradient projeté."
      ],
      "metadata": {
        "id": "3kK7d0xWrQqh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Discussion et interpretation des résultats trouvés"
      ],
      "metadata": {
        "id": "Vhuf_4DqwfWI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Au vu des résultats trouvés au préalable, la méthode du gradient projeté et de cvxpy peuvent utiliser différentes formulations pour résoudre le problème d'optimisation. Cela inclut les contraintes, les objectifs et les algorithmes spécifiques utilisés. Les différences dans la formulation peuvent conduire à des solutions légèrement différentes. De plus, les 2 méthodes sont relativement différentes. Le gradient projeté est basé sur la descente de gradient avec une projection sur l'ensemble des contraintes ($K$ dans notre cas), tandis que cvxpy peut utiliser des méthodes d'optimisation convexe plus sophistiquées et spécialisées. Ces différences en elles-mêmes peuvent créer des résultats pratiquement différents.\n",
        "\n",
        "Les légères différences peuvent bien entendu être aussi attribuées à des erreurs numériques ou à des approximations numériques dans les calculs effectués par les 2 méthodes, notamment, pour la méthode du gradient projeté, car on choisit manuellement la tolérance (seuil d'arrêt), le pas de descente (alpha) ou autre. Cela étant dit, ces calculs numériques peuvent introduire de petites variations dans les résultats obtenus.\n",
        "\n",
        "Il est aussi important de souligner que la méthode utilisée par cvxpy est plus rapide dans notre cas, cette méthode est conçu pour exploiter les propriétés du problème d'optimisation spécifique et trouver rapidement la solution.\n",
        "En outre, la méthode du gradient projeté est basée sur une itération de la projection du gradient, ce qui peut nécessiter un plus grand nombre d'itérations pour converger vers la solution optimale. Tandis que la méthode de cvxpy est basée sur une optimisation convexe qui permet d’assurer une convergence plus rapide et cela ne peut être justifiée que par les résultats trouvés. Nonobstant, il se peut, dans cetains cas, que la méthode du gradient projeté soit plus optimale en terme de précision de la solution par rapport à l'autre méthode, malgré la rapidité de cette dérnière."
      ],
      "metadata": {
        "id": "FJ0HXDDlxcx0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5 Conclusion <a id=\"1\"></a>"
      ],
      "metadata": {
        "id": "QOugWrBA5Pkj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "L’ optimisation du portefeuille grâce à la théorie moderne du portefeuille peut être un moyen efficace d’obtenir des rendements plus élevés et une meilleure gestion des risques.\n",
        "\n",
        "Toutefois, il est important de noter que la théorie moderne des portefeuilles présente certains inconvénients, notamment le fait que les portefeuilles sont évalués en fonction de la variance plutôt que du risque de baisse. Cela signifie que même si l’optimisation du portefeuille peut améliorer le rendement global, elle ne protège pas nécessairement contre les événements extrêmes du marché ou les risques de baisse.\n",
        "\n",
        "Bien que la théorie moderne des portefeuilles comporte des limites, elle demeure un outil très utile pour les investisseurs qui cherchent à diversifier leurs portefeuilles et à améliorer la gestion des risques."
      ],
      "metadata": {
        "id": "r5SKpWaY5S4w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> \"*Tous les modèles sont erronés, mais certains sont utiles.*\" ~ George Box\n",
        "\n",
        "> \"*Le talent remplit les pages, mais la persévérance complète les chapitres.*\" ~ C.J. Cherryh\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YxvnHT1B6H-E"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}